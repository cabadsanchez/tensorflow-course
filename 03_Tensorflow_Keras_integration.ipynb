{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow keras integration\n",
    " - Base keras model\n",
    " - Tensorflow to control the training process\n",
    " - Combine Tensorflow layers and keras layers\n",
    " - Use tensorboard to show the net & the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  1.4.0\n"
     ]
    }
   ],
   "source": [
    "# Header\n",
    "# Basic libraries & options\n",
    "from __future__ import print_function\n",
    "\n",
    "#Basic libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print('Tensorflow version: ', tf.__version__)\n",
    "import time\n",
    "\n",
    "# Select GPU\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "#Show images\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# plt configuration\n",
    "plt.rcParams['figure.figsize'] = (10, 10)        # size of images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # show exact image\n",
    "plt.rcParams['image.cmap'] = 'gray'  # use grayscale \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data(path='mnist.npz')\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 2s - loss: 1.0890 - acc: 0.7698 - val_loss: 0.5985 - val_acc: 0.8653\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.5208 - acc: 0.8729 - val_loss: 0.4343 - val_acc: 0.8905\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.4196 - acc: 0.8898 - val_loss: 0.3739 - val_acc: 0.9029\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.3736 - acc: 0.8987 - val_loss: 0.3413 - val_acc: 0.9087\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.3453 - acc: 0.9050 - val_loss: 0.3198 - val_acc: 0.9137\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.3252 - acc: 0.9097 - val_loss: 0.3031 - val_acc: 0.9167\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.3096 - acc: 0.9140 - val_loss: 0.2898 - val_acc: 0.9209\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.2968 - acc: 0.9171 - val_loss: 0.2799 - val_acc: 0.9240\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.2857 - acc: 0.9200 - val_loss: 0.2713 - val_acc: 0.9251\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.2762 - acc: 0.9226 - val_loss: 0.2631 - val_acc: 0.9279\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.2676 - acc: 0.9251 - val_loss: 0.2553 - val_acc: 0.9281\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.2597 - acc: 0.9279 - val_loss: 0.2485 - val_acc: 0.9309\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.2524 - acc: 0.9294 - val_loss: 0.2419 - val_acc: 0.9327\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.2457 - acc: 0.9316 - val_loss: 0.2359 - val_acc: 0.9337\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.2393 - acc: 0.9334 - val_loss: 0.2320 - val_acc: 0.9349\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.2334 - acc: 0.9351 - val_loss: 0.2256 - val_acc: 0.9368\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.2278 - acc: 0.9370 - val_loss: 0.2209 - val_acc: 0.9379\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.2224 - acc: 0.9381 - val_loss: 0.2163 - val_acc: 0.9387\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.2173 - acc: 0.9394 - val_loss: 0.2114 - val_acc: 0.9392\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.2125 - acc: 0.9411 - val_loss: 0.2070 - val_acc: 0.9413\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.2079 - acc: 0.9419 - val_loss: 0.2030 - val_acc: 0.9425\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.2034 - acc: 0.9435 - val_loss: 0.1997 - val_acc: 0.9432\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1992 - acc: 0.9448 - val_loss: 0.1955 - val_acc: 0.9445\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1950 - acc: 0.9458 - val_loss: 0.1915 - val_acc: 0.9454\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1912 - acc: 0.9469 - val_loss: 0.1884 - val_acc: 0.9461\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1874 - acc: 0.9477 - val_loss: 0.1850 - val_acc: 0.9478\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1837 - acc: 0.9490 - val_loss: 0.1823 - val_acc: 0.9489\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1802 - acc: 0.9497 - val_loss: 0.1790 - val_acc: 0.9494\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1768 - acc: 0.9507 - val_loss: 0.1758 - val_acc: 0.9505\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1735 - acc: 0.9516 - val_loss: 0.1733 - val_acc: 0.9500\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1705 - acc: 0.9527 - val_loss: 0.1701 - val_acc: 0.9518\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1674 - acc: 0.9536 - val_loss: 0.1682 - val_acc: 0.9515\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1645 - acc: 0.9543 - val_loss: 0.1652 - val_acc: 0.9531\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1616 - acc: 0.9553 - val_loss: 0.1626 - val_acc: 0.9541\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1589 - acc: 0.9558 - val_loss: 0.1594 - val_acc: 0.9546\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1563 - acc: 0.9570 - val_loss: 0.1574 - val_acc: 0.9550\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1537 - acc: 0.9575 - val_loss: 0.1552 - val_acc: 0.9559\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1513 - acc: 0.9582 - val_loss: 0.1539 - val_acc: 0.9553\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1488 - acc: 0.9588 - val_loss: 0.1514 - val_acc: 0.9576\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1465 - acc: 0.9600 - val_loss: 0.1491 - val_acc: 0.9572\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1443 - acc: 0.9604 - val_loss: 0.1475 - val_acc: 0.9572\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1421 - acc: 0.9608 - val_loss: 0.1458 - val_acc: 0.9582\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1399 - acc: 0.9615 - val_loss: 0.1439 - val_acc: 0.9585\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1378 - acc: 0.9619 - val_loss: 0.1427 - val_acc: 0.9593\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1359 - acc: 0.9628 - val_loss: 0.1401 - val_acc: 0.9597\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1339 - acc: 0.9630 - val_loss: 0.1385 - val_acc: 0.9608\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1321 - acc: 0.9636 - val_loss: 0.1370 - val_acc: 0.9613\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1302 - acc: 0.9644 - val_loss: 0.1356 - val_acc: 0.9617\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1283 - acc: 0.9648 - val_loss: 0.1337 - val_acc: 0.9617\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 2s - loss: 0.1265 - acc: 0.9653 - val_loss: 0.1322 - val_acc: 0.9622\n"
     ]
    }
   ],
   "source": [
    "# Base Keras Model\n",
    "images = tf.keras.layers.Input(batch_shape=(None, 28, 28), dtype='float32', name='Images')\n",
    "\n",
    "flat   = tf.keras.layers.Flatten(name='Flat_image')(images)\n",
    "dense  = tf.keras.layers.Dense(500, activation='relu', name='Dense_layer')(flat)\n",
    "output = tf.keras.layers.Dense(10, activation='softmax', name='Dense_output')(dense)\n",
    "\n",
    "model_linear = tf.keras.models.Model(inputs=images, outputs=output)\n",
    "\n",
    "# Train\n",
    "model_linear.compile(loss='sparse_categorical_crossentropy',\n",
    "                     optimizer=tf.keras.optimizers.SGD(lr=0.01), metrics=['accuracy'])\n",
    "\n",
    "history_linear = model_linear.fit(X_train, y_train, batch_size=128, epochs=50,\n",
    "                                  verbose=1, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow to control the training process\n",
    "    - use a batch generator\n",
    "    - Implement a basic training process\n",
    "        - Create placeholders\n",
    "        - Create a loss function\n",
    "        - Create a trainer\n",
    "        - Define an accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start interactive session\n",
    "sess = tf.InteractiveSession()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input placeholders\n",
    "x = tf.placeholder(tf.float32, shape=[None, 28, 28])\n",
    "y = tf.placeholder(tf.int64, shape=[None, ])\n",
    "\n",
    "# Define model using Keras layers\n",
    "flat   = tf.keras.layers.Flatten(name='Flat_image')(x)\n",
    "dense  = tf.keras.layers.Dense(500, activation='relu', name='Dense_layer')(flat)\n",
    "output = tf.keras.layers.Dense(10, activation='relu', name='Dense_output')(dense)\n",
    "\n",
    "# Define the Tensorflow Loss\n",
    "cross_entropy = tf.losses.sparse_softmax_cross_entropy(y, output)\n",
    "\n",
    "# Define the Tensorflow Train function\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "# Create an Accuracy metric to evaluate in test\n",
    "y_pred = tf.nn.softmax(output)\n",
    "correct_prediction = tf.equal(y, tf.argmax(y_pred,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a generator to data. Same code to an HDF5 source\n",
    "def batch_generator(X, y, batch_size=64):\n",
    "    data_size = X.shape[0]\n",
    "    # Randomize batches in each epoch\n",
    "    batch_randomized = np.random.permutation(range(0, data_size-batch_size, batch_size))\n",
    "    # Iterate over each batch\n",
    "    for batch in batch_randomized:\n",
    "        x_batch = X[batch : batch+batch_size]\n",
    "        y_batch = y[batch : batch+batch_size]\n",
    "        yield x_batch, y_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Intialize vars\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7828\n",
      "1 0.8836\n",
      "2 0.8999\n",
      "3 0.9081\n",
      "4 0.9129\n",
      "5 0.916\n",
      "6 0.9218\n",
      "7 0.9254\n",
      "8 0.9269\n",
      "9 0.9284\n",
      "10 0.9298\n",
      "11 0.9323\n",
      "12 0.9347\n",
      "13 0.9357\n",
      "14 0.9379\n",
      "15 0.9381\n",
      "16 0.9401\n",
      "17 0.9414\n",
      "18 0.9409\n",
      "19 0.9427\n",
      "20 0.9442\n",
      "21 0.9448\n",
      "22 0.9448\n",
      "23 0.9471\n",
      "24 0.9468\n",
      "25 0.9485\n",
      "26 0.9479\n",
      "27 0.9495\n",
      "28 0.9503\n",
      "29 0.9511\n",
      "30 0.9524\n",
      "31 0.9526\n",
      "32 0.9539\n",
      "33 0.9539\n",
      "34 0.9549\n",
      "35 0.9553\n",
      "36 0.9557\n",
      "37 0.9565\n",
      "38 0.957\n",
      "39 0.9576\n",
      "40 0.9588\n",
      "41 0.9583\n",
      "42 0.9588\n",
      "43 0.9593\n",
      "44 0.9594\n",
      "45 0.9603\n",
      "46 0.9614\n",
      "47 0.9614\n",
      "48 0.9617\n",
      "49 0.9621\n"
     ]
    }
   ],
   "source": [
    "# Basic iterator over the epochs and the batches to execute the trainer. \n",
    "batch_size = 128\n",
    "num_epoch = 50\n",
    "for epoch in range(num_epoch):\n",
    "    for x_batch, y_batch in  batch_generator(X_train, y_train, batch_size=batch_size):\n",
    "        train_step.run(feed_dict={x: x_batch, y: y_batch})\n",
    "    print(epoch, accuracy.eval(feed_dict={x: X_test, y: y_test}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10 Accuracy:  0.731\n",
      "Epoch:  20 Accuracy:  0.7429\n",
      "Epoch:  30 Accuracy:  0.7489\n",
      "Epoch:  40 Accuracy:  0.7532\n",
      "Epoch:  50 Accuracy:  0.7566\n",
      "Epoch:  60 Accuracy:  0.7594\n",
      "Epoch:  70 Accuracy:  0.7622\n",
      "Epoch:  80 Accuracy:  0.7637\n",
      "Epoch:  90 Accuracy:  0.7656\n",
      "Epoch:  100 Accuracy:  0.7666\n",
      "Epoch:  110 Accuracy:  0.768\n",
      "Epoch:  120 Accuracy:  0.7689\n",
      "Epoch:  130 Accuracy:  0.7695\n",
      "STOP. Accuracy:  0.7692\n"
     ]
    }
   ],
   "source": [
    "# Intialize vars\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Early stopping code. Stop if the current accuray is < that the min of the last 5 epochs. \n",
    "batch_size = 128\n",
    "acc_test=[]\n",
    "epoch=0\n",
    "stop=True\n",
    "\n",
    "while stop:\n",
    "    #Train\n",
    "    epoch += 1\n",
    "    for x_batch, y_batch in  batch_generator(X_train, y_train, batch_size=batch_size):\n",
    "        train_step.run(feed_dict={x: x_batch, y: y_batch})\n",
    "\n",
    "    # Test\n",
    "    acc_test += [accuracy.eval(feed_dict={x: X_test, y: y_test})]\n",
    "    if epoch%10==0:\n",
    "        print('Epoch: ', epoch, 'Accuracy: ', acc_test[-1])\n",
    "\n",
    "    # Stopping criteria\n",
    "    if epoch>10 and acc_test[-1] < min(acc_test[-10:-1]):\n",
    "        stop=False\n",
    "        print('STOP. Accuracy: ', acc_test[-1])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#When finish, close the interactive session\n",
    "sess.close()\n",
    "\n",
    "# Reset the graph to the next experiments\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow layers and keras layers\n",
    "    - Combine Keras layers with tensorflow layers\n",
    "    - Monitor layers in tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat layer:  Tensor(\"Flat_image_2/Reshape:0\", shape=(?, 320), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Start interactive session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "\n",
    "# Convolutional model\n",
    "x = tf.placeholder(tf.float32, shape=[None, 28, 28])\n",
    "y = tf.placeholder(tf.int64, shape=[None, ])\n",
    "\n",
    "image = tf.reshape(x,[-1,28,28,1])\n",
    "\n",
    "conv1 = tf.keras.layers.Conv2D(20, (5,5))(image)\n",
    "pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = tf.keras.layers.Conv2D(20, (5,5))(pool1)\n",
    "pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "flat = tf.keras.layers.Flatten(name='Flat_image')(pool2)\n",
    "print('Flat layer: ', flat)\n",
    "\n",
    "\n",
    "# Tensorflow Dense layer\n",
    "W_dense = tf.Variable(tf.truncated_normal([320, 500], stddev=0.1), name='W_dense')\n",
    "b_dense = tf.Variable(tf.constant(0.1, shape=[500]), name='b_dense')\n",
    "dense1 = tf.nn.relu(tf.matmul(flat, W_dense) + b_dense)\n",
    "#dense1 = layers.Dense(500, activation='relu', name='Dense_1')(flat)\n",
    "\n",
    "\n",
    "output = tf.keras.layers.Dense(10, activation='linear', name='Dense_output')(dense1)\n",
    "\n",
    "# Define the Tensorflow Loss\n",
    "cross_entropy = tf.losses.sparse_softmax_cross_entropy(y, output)\n",
    "\n",
    "# Define the Tensorflow Train function\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "# Create an Accuracy metric to evaluate in test\n",
    "y_pred = tf.nn.softmax(output)\n",
    "correct_prediction = tf.equal(y, tf.argmax(y_pred,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 Accuracy:  0.912\n",
      "Epoch:  2 Accuracy:  0.9403\n",
      "Epoch:  3 Accuracy:  0.9502\n",
      "Epoch:  4 Accuracy:  0.9619\n",
      "Epoch:  5 Accuracy:  0.9662\n",
      "Epoch:  6 Accuracy:  0.9688\n",
      "Epoch:  7 Accuracy:  0.9719\n",
      "Epoch:  8 Accuracy:  0.9732\n",
      "Epoch:  9 Accuracy:  0.977\n",
      "Epoch:  10 Accuracy:  0.98\n",
      "Epoch:  11 Accuracy:  0.9788\n",
      "Epoch:  12 Accuracy:  0.9799\n",
      "Epoch:  13 Accuracy:  0.9777\n",
      "Epoch:  14 Accuracy:  0.9806\n",
      "Epoch:  15 Accuracy:  0.9817\n",
      "Epoch:  16 Accuracy:  0.9823\n",
      "Epoch:  17 Accuracy:  0.9821\n",
      "Epoch:  18 Accuracy:  0.9824\n",
      "Epoch:  19 Accuracy:  0.9826\n",
      "Epoch:  20 Accuracy:  0.9833\n",
      "Epoch:  21 Accuracy:  0.9819\n",
      "Epoch:  22 Accuracy:  0.9788\n",
      "Epoch:  23 Accuracy:  0.9835\n",
      "Epoch:  24 Accuracy:  0.9826\n",
      "Epoch:  25 Accuracy:  0.9829\n",
      "Epoch:  26 Accuracy:  0.9843\n",
      "Epoch:  27 Accuracy:  0.9848\n",
      "Epoch:  28 Accuracy:  0.9841\n",
      "Epoch:  29 Accuracy:  0.9842\n",
      "Epoch:  30 Accuracy:  0.9852\n",
      "Epoch:  31 Accuracy:  0.9854\n",
      "Epoch:  32 Accuracy:  0.9836\n",
      "Epoch:  33 Accuracy:  0.9849\n",
      "Epoch:  34 Accuracy:  0.9853\n",
      "Epoch:  35 Accuracy:  0.9849\n",
      "Epoch:  36 Accuracy:  0.9858\n",
      "Epoch:  37 Accuracy:  0.9853\n",
      "Epoch:  38 Accuracy:  0.9851\n",
      "Epoch:  39 Accuracy:  0.9856\n",
      "Epoch:  40 Accuracy:  0.9852\n",
      "Epoch:  41 Accuracy:  0.9851\n",
      "Epoch:  42 Accuracy:  0.9865\n",
      "Epoch:  43 Accuracy:  0.9859\n",
      "Epoch:  44 Accuracy:  0.987\n",
      "Epoch:  45 Accuracy:  0.9866\n",
      "Epoch:  46 Accuracy:  0.9858\n",
      "Epoch:  47 Accuracy:  0.9865\n",
      "Epoch:  48 Accuracy:  0.9852\n",
      "Epoch:  49 Accuracy:  0.9859\n",
      "Epoch:  50 Accuracy:  0.9852\n",
      "Epoch:  51 Accuracy:  0.9855\n",
      "Epoch:  52 Accuracy:  0.9865\n",
      "Epoch:  53 Accuracy:  0.9864\n",
      "Epoch:  54 Accuracy:  0.9871\n",
      "Epoch:  55 Accuracy:  0.9857\n",
      "Epoch:  56 Accuracy:  0.9864\n",
      "Epoch:  57 Accuracy:  0.9858\n",
      "Epoch:  58 Accuracy:  0.9863\n",
      "Epoch:  59 Accuracy:  0.9862\n",
      "Epoch:  60 Accuracy:  0.9865\n",
      "Epoch:  61 Accuracy:  0.9872\n",
      "Epoch:  62 Accuracy:  0.9859\n",
      "Epoch:  63 Accuracy:  0.9874\n",
      "Epoch:  64 Accuracy:  0.9866\n",
      "Epoch:  65 Accuracy:  0.9872\n",
      "Epoch:  66 Accuracy:  0.9857\n",
      "STOP. Accuracy:  0.9857\n"
     ]
    }
   ],
   "source": [
    "# Intialize vars\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Early stopping code. Stop if the current accuray is < that the min of the last 5 epochs. \n",
    "batch_size = 128\n",
    "acc_test=[]\n",
    "epoch=0\n",
    "stop=True\n",
    "\n",
    "while stop:\n",
    "    #Train\n",
    "    epoch += 1\n",
    "    for x_batch, y_batch in  batch_generator(X_train, y_train, batch_size=batch_size):\n",
    "        train_step.run(feed_dict={x: x_batch, y: y_batch})\n",
    "\n",
    "    # Test\n",
    "    acc_test += [accuracy.eval(feed_dict={x: X_test, y: y_test})]\n",
    "    if epoch%1==0:\n",
    "        print('Epoch: ', epoch, 'Accuracy: ', acc_test[-1])\n",
    "\n",
    "    # Stopping criteria\n",
    "    if epoch>10 and acc_test[-1] < min(acc_test[-10:-1]):\n",
    "        stop=False\n",
    "        print('STOP. Accuracy: ', acc_test[-1])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#When finish, close the interactive session\n",
    "sess.close()\n",
    "\n",
    "# Reset the graph to the next experiments\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use tensorboard to show the net & the training process.\n",
    "    - The same previous convolutional model with the commands that need tensorboard\n",
    "\n",
    "Based on https://www.tensorflow.org/how_tos/summaries_and_tensorboard/index.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var, name):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor.\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean/'   + name, mean)\n",
    "        tf.summary.scalar('sttdev/' + name, tf.sqrt(tf.reduce_mean(tf.square(var - mean))))\n",
    "        tf.summary.scalar('max/'    + name, tf.reduce_max(var))\n",
    "        tf.summary.scalar('min/'    + name, tf.reduce_min(var))\n",
    "        tf.summary.histogram(name, var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0b7b3fc90e9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mvariable_summaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dense1_summary\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Summaries of the layer output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Dense_output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Define the Tensorflow Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'layers' is not defined"
     ]
    }
   ],
   "source": [
    "# Start interactive session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "\n",
    "# Convolutional model\n",
    "x = tf.placeholder(tf.float32, shape=[None, 28, 28])\n",
    "y = tf.placeholder(tf.int64, shape=[None, ])\n",
    "\n",
    "image = tf.reshape(x,[-1,28,28,1])\n",
    "\n",
    "with tf.name_scope('Conv1') as scope:\n",
    "    conv1 = tf.keras.layers.Conv2D(20, (5,5))(image)\n",
    "    pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    variable_summaries(pool1, \"pool1_summary\")\n",
    "\n",
    "with tf.name_scope('Conv2') as scope:\n",
    "    conv2 = tf.keras.layers.Conv2D(20, (5,5))(pool1)\n",
    "    pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    variable_summaries(pool2, \"pool2_summary\")\n",
    "\n",
    "with tf.name_scope('Dense') as scope:\n",
    "    flat = tf.keras.layers.Flatten(name='Flat_image')(pool2)\n",
    "    # Tensorflow Dense layer\n",
    "    W_dense = tf.Variable(tf.truncated_normal([320, 500], stddev=0.1), name='W_dense')\n",
    "    variable_summaries(W_dense, \"W_dense_summary\") # Summaries of the layer weigths\n",
    "    b_dense = tf.Variable(tf.constant(0.1, shape=[500]), name='b_dense')\n",
    "    variable_summaries(b_dense, \"b_dense_summary\") # Summaries of the layer weigths\n",
    "    dense1 = tf.nn.relu(tf.matmul(flat, W_dense) + b_dense)\n",
    "    variable_summaries(dense1, \"dense1_summary\") # Summaries of the layer output\n",
    "\n",
    "    output = layers.Dense(10, activation='linear', name='Dense_output')(dense1)\n",
    "\n",
    "# Define the Tensorflow Loss\n",
    "#with tf.name_scope('loss') as scope:\n",
    "cross_entropy = tf.losses.sparse_softmax_cross_entropy(y, output)\n",
    "loss_summary = tf.summary.scalar(\"loss\", cross_entropy)\n",
    "    \n",
    "# Define the Tensorflow Train function\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "# Create an Accuracy metric to evaluate in test\n",
    "#with tf.name_scope('acc') as scope:\n",
    "y_pred = tf.nn.softmax(output)\n",
    "correct_prediction = tf.equal(y, tf.argmax(y_pred,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "accuracy_summary = tf.summary.scalar(\"acc\", accuracy)\n",
    "\n",
    "# Add summaries to the graph\n",
    "summaries_dir = '/tmp/tensorboard/tf'\n",
    "with tf.name_scope('summaries') as scope:\n",
    "    merged = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter(summaries_dir + '/train', sess.graph)\n",
    "    test_writer  = tf.summary.FileWriter(summaries_dir + '/test')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize vars\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Early stopping code. Stop if the current accuray is < that the min of the last 5 epochs. \n",
    "batch_size = 128\n",
    "acc_test=[]\n",
    "epoch=0\n",
    "stop=True\n",
    "while stop:\n",
    "    #Train\n",
    "    epoch += 1\n",
    "    counter = 0\n",
    "    for x_batch, y_batch in  batch_generator(X_train, y_train, batch_size=batch_size):\n",
    "        train_step.run(feed_dict={x: x_batch, y: y_batch})\n",
    "        \n",
    "        counter += 1\n",
    "        if counter%10 == 0:\n",
    "            summary_str = merged.eval(feed_dict={x: x_batch, y: y_batch}) #TENSORBOARD\n",
    "            train_writer.add_summary(summary_str, epoch) #TENSORBOARD\n",
    "            \n",
    "                \n",
    "    # Test\n",
    "    acc_test += [accuracy.eval(feed_dict={x: X_test, y: y_test})]\n",
    "    \n",
    "    summary_str = merged.eval(feed_dict={x: X_test, y: y_test}) #TENSORBOARD \n",
    "    test_writer.add_summary(summary_str, epoch) #TENSORBOARD \n",
    "      \n",
    "    if epoch%1==0:\n",
    "        print('Epoch: ', epoch, 'Accuracy: ', acc_test[-1])\n",
    "\n",
    "    # Stopping criteria\n",
    "    if epoch>10 and acc_test[-1] < min(acc_test[-10:-1]):\n",
    "        stop=False\n",
    "        print('STOP. Accuracy: ', acc_test[-1])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end execute tensorboar with:\n",
    "\n",
    "    cd /tmp\n",
    "\n",
    "    tensorboard --logdir=./tensorboard\n",
    "\n",
    "And accest to it in:\n",
    "\n",
    "    http://<My_server_IP>:6006\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf14]",
   "language": "python",
   "name": "conda-env-tf14-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
