{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standar usage of TensoFlow with model class\n",
    "\n",
    "Tipically use 3 files:\n",
    " - data_utils.py: With the data access and batch generator functions\n",
    " - model.py: With the class model. A constructor with the graph definition and method to manage model needs\n",
    " - train.py: With parameters. Access to the data, instance the model and train it. Optionaly add a parameter to train or inference.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/anaconda3/envs/tm/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Access to the data\n",
    "def get_data(data_dir='/tmp/MNIST_data'):\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    return input_data.read_data_sets(data_dir, one_hot=True)\n",
    "\n",
    "\n",
    "#Batch generator\n",
    "def batch_generator(mnist, batch_size=256, type='train'):\n",
    "    if type=='train':\n",
    "        return mnist.train.next_batch(batch_size)\n",
    "    else:\n",
    "        return mnist.test.next_batch(batch_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model_mnist_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "class mnistCNN(object):\n",
    "    \"\"\"\n",
    "    A NN for mnist classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, dense=500):\n",
    "    \n",
    "        # Placeholders for input, output and dropout\n",
    "        self.input_x = tf.placeholder(tf.float32, [None, 784], name=\"input_x\")\n",
    "        self.input_y = tf.placeholder(tf.float32, [None, 10], name=\"input_y\")\n",
    "    \n",
    "        # First layer\n",
    "        self.dense_1 = self.dense_layer(self.input_x, input_dim=784, output_dim=dense)\n",
    "\n",
    "        # Final layer\n",
    "        self.dense_2 = self.dense_layer(self.dense_1, input_dim=dense, output_dim=10)\n",
    "\n",
    "        self.predictions = tf.argmax(self.dense_2, 1, name=\"predictions\")\n",
    "        \n",
    "        # Loss function\n",
    "        self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.dense_2, labels=self.input_y))\n",
    "        \n",
    "        # Accuracy\n",
    "        correct_predictions = tf.equal(self.predictions, tf.argmax(self.input_y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")\n",
    "    \n",
    "\n",
    "    def dense_layer(self, x, input_dim=10, output_dim=10, name='dense'):\n",
    "        '''\n",
    "        Dense layer function\n",
    "        Inputs:\n",
    "          x: Input tensor\n",
    "          input_dim: Dimmension of the input tensor.\n",
    "          output_dim: dimmension of the output tensor\n",
    "          name: Layer name\n",
    "        '''\n",
    "        W = tf.Variable(tf.truncated_normal([input_dim, output_dim], stddev=0.1), name='W_'+name)\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[output_dim]), name='b_'+name)\n",
    "        dense_output = tf.nn.relu(tf.matmul(x, W) + b)\n",
    "        return dense_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jorge/anaconda3/envs/tm/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-1-517d7fd89976>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/jorge/anaconda3/envs/tm/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/jorge/anaconda3/envs/tm/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/jorge/anaconda3/envs/tm/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/jorge/anaconda3/envs/tm/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /tmp/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/jorge/anaconda3/envs/tm/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-2-155fb17a5467>:24: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "0 0.17388675 0.953125\n",
      "1 0.20837279 0.94921875\n",
      "2 0.08163881 0.98046875\n",
      "3 0.06509758 0.98046875\n",
      "4 0.04458614 0.9921875\n",
      "5 0.031652514 0.98828125\n",
      "6 0.031860538 0.98828125\n",
      "7 0.0152565595 0.99609375\n",
      "8 0.025273293 0.9921875\n",
      "9 0.02078941 0.99609375\n",
      "10 0.011658609 1.0\n",
      "11 0.008949763 1.0\n",
      "12 0.010515677 0.99609375\n",
      "13 0.008559352 1.0\n",
      "14 0.0039603636 1.0\n",
      "15 0.0042274096 1.0\n",
      "16 0.002513728 1.0\n",
      "17 0.0015000642 1.0\n",
      "18 0.0028359129 1.0\n",
      "19 0.001982538 1.0\n",
      "Model saved in /tmp/mnist_model\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#from data_utils import get_data, batch_generator\n",
    "#from model_mnist_cnn import mnistCNN\n",
    "\n",
    "\n",
    "# Parameters\n",
    "# ==================================================\n",
    "\n",
    "# Data loading params\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel') # To run in notebook\n",
    "\n",
    "tf.flags.DEFINE_string(\"data_directory\", '/tmp/MNIST_data', \"Data dir (default /tmp/MNIST_data)\")\n",
    "\n",
    "# Model Hyperparameters\n",
    "tf.flags.DEFINE_integer(\"dense_size\", 500, \"dense_size (default 500)\")\n",
    "\n",
    "# Training parameters\n",
    "tf.flags.DEFINE_float(\"learning_rate\", 0.001, \"learning rate (default: 0.001)\")\n",
    "tf.flags.DEFINE_integer(\"batch_size\", 256, \"Batch Size (default: 256)\")\n",
    "tf.flags.DEFINE_integer(\"num_epochs\", 20, \"Number of training epochs (default: 20)\")\n",
    "\n",
    "# Misc Parameters\n",
    "tf.flags.DEFINE_boolean(\"log_device_placement\", False, \"Log placement of ops on devices\")\n",
    "\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "\n",
    "\n",
    "\n",
    "# Data Preparation\n",
    "# ==================================================\n",
    "\n",
    "#Access to the data\n",
    "mnist_data = get_data(data_dir= FLAGS.data_directory)\n",
    "\n",
    "\n",
    "# Training\n",
    "# ==================================================\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333, allow_growth = True)\n",
    "with tf.Graph().as_default():\n",
    "    session_conf = tf.ConfigProto(\n",
    "        gpu_options=gpu_options,\n",
    "        log_device_placement=FLAGS.log_device_placement)\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    with sess.as_default():\n",
    "        \n",
    "        # Create model\n",
    "        cnn = mnistCNN(dense=FLAGS.dense_size)\n",
    "        \n",
    "        # Trainer\n",
    "        train_op = tf.train.AdamOptimizer(FLAGS.learning_rate).minimize(cnn.loss)\n",
    "\n",
    "        # Saver\n",
    "        saver = tf.train.Saver(max_to_keep=1)\n",
    "\n",
    "        # Initialize all variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Train proccess\n",
    "        for epoch in range(FLAGS.num_epochs):\n",
    "            for n_batch in range(int(55000/FLAGS.batch_size)):\n",
    "                batch = batch_generator(mnist_data, batch_size=FLAGS.batch_size, type='train')\n",
    "                _, ce, acc = sess.run([train_op, cnn.loss, cnn.accuracy], feed_dict={cnn.input_x: batch[0], cnn.input_y: batch[1]})\n",
    "\n",
    "            print(epoch, ce, acc)\n",
    "        model_file = saver.save(sess, '/tmp/mnist_model')\n",
    "        print('Model saved in', model_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tm]",
   "language": "python",
   "name": "conda-env-tm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
